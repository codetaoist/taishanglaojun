groups:
  - name: taishanglaojun.rules
    rules:
      # Application Health Alerts
      - alert: ApplicationDown
        expr: up{job=~"taishanglaojun-.*"} == 0
        for: 1m
        labels:
          severity: critical
          service: "{{ $labels.job }}"
        annotations:
          summary: "Taishang Laojun service is down"
          description: "{{ $labels.job }} has been down for more than 1 minute."

      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m]) > 0.05
        for: 5m
        labels:
          severity: warning
          service: "{{ $labels.job }}"
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value | humanizePercentage }} for {{ $labels.job }}"

      - alert: HighLatency
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 1
        for: 5m
        labels:
          severity: warning
          service: "{{ $labels.job }}"
        annotations:
          summary: "High latency detected"
          description: "95th percentile latency is {{ $value }}s for {{ $labels.job }}"

      # Resource Usage Alerts
      - alert: HighCPUUsage
        expr: rate(container_cpu_usage_seconds_total{container!="POD",container!=""}[5m]) * 100 > 80
        for: 10m
        labels:
          severity: warning
          service: "{{ $labels.container }}"
        annotations:
          summary: "High CPU usage"
          description: "Container {{ $labels.container }} CPU usage is {{ $value }}%"

      - alert: HighMemoryUsage
        expr: container_memory_usage_bytes{container!="POD",container!=""} / container_spec_memory_limit_bytes * 100 > 90
        for: 5m
        labels:
          severity: critical
          service: "{{ $labels.container }}"
        annotations:
          summary: "High memory usage"
          description: "Container {{ $labels.container }} memory usage is {{ $value }}%"

      - alert: PodCrashLooping
        expr: rate(kube_pod_container_status_restarts_total[15m]) > 0
        for: 5m
        labels:
          severity: warning
          service: "{{ $labels.pod }}"
        annotations:
          summary: "Pod is crash looping"
          description: "Pod {{ $labels.pod }} is restarting frequently"

      # Database Alerts
      - alert: DatabaseConnectionsHigh
        expr: pg_stat_database_numbackends / pg_settings_max_connections * 100 > 80
        for: 5m
        labels:
          severity: warning
          service: "postgresql"
        annotations:
          summary: "High database connections"
          description: "PostgreSQL connections are at {{ $value }}% of maximum"

      - alert: DatabaseSlowQueries
        expr: rate(pg_stat_database_tup_returned[5m]) / rate(pg_stat_database_tup_fetched[5m]) < 0.1
        for: 10m
        labels:
          severity: warning
          service: "postgresql"
        annotations:
          summary: "Database slow queries detected"
          description: "PostgreSQL query efficiency is low: {{ $value }}"

      # Redis Alerts
      - alert: RedisDown
        expr: redis_up == 0
        for: 1m
        labels:
          severity: critical
          service: "redis"
        annotations:
          summary: "Redis is down"
          description: "Redis instance is not responding"

      - alert: RedisHighMemoryUsage
        expr: redis_memory_used_bytes / redis_memory_max_bytes * 100 > 90
        for: 5m
        labels:
          severity: warning
          service: "redis"
        annotations:
          summary: "Redis high memory usage"
          description: "Redis memory usage is {{ $value }}%"

      # Kubernetes Cluster Alerts
      - alert: NodeNotReady
        expr: kube_node_status_condition{condition="Ready",status="true"} == 0
        for: 5m
        labels:
          severity: critical
          service: "kubernetes"
        annotations:
          summary: "Node is not ready"
          description: "Node {{ $labels.node }} is not ready"

      - alert: PodNotReady
        expr: kube_pod_status_ready{condition="true"} == 0
        for: 10m
        labels:
          severity: warning
          service: "kubernetes"
        annotations:
          summary: "Pod is not ready"
          description: "Pod {{ $labels.pod }} in namespace {{ $labels.namespace }} is not ready"

      - alert: DeploymentReplicasMismatch
        expr: kube_deployment_spec_replicas != kube_deployment_status_available_replicas
        for: 10m
        labels:
          severity: warning
          service: "kubernetes"
        annotations:
          summary: "Deployment replicas mismatch"
          description: "Deployment {{ $labels.deployment }} has {{ $value }} available replicas, expected {{ $labels.spec_replicas }}"

      # Storage Alerts
      - alert: PersistentVolumeUsageHigh
        expr: kubelet_volume_stats_used_bytes / kubelet_volume_stats_capacity_bytes * 100 > 85
        for: 5m
        labels:
          severity: warning
          service: "storage"
        annotations:
          summary: "Persistent volume usage high"
          description: "PV {{ $labels.persistentvolumeclaim }} usage is {{ $value }}%"

      # Network Alerts
      - alert: HighNetworkReceiveErrors
        expr: rate(node_network_receive_errs_total[5m]) > 10
        for: 5m
        labels:
          severity: warning
          service: "network"
        annotations:
          summary: "High network receive errors"
          description: "Network interface {{ $labels.device }} has high receive error rate: {{ $value }}"

      # Security Alerts
      - alert: TooManyFailedLogins
        expr: rate(failed_login_attempts_total[5m]) > 5
        for: 2m
        labels:
          severity: warning
          service: "security"
        annotations:
          summary: "Too many failed login attempts"
          description: "High rate of failed login attempts: {{ $value }} per second"

      - alert: SuspiciousAPIActivity
        expr: rate(http_requests_total{status="401"}[5m]) > 10
        for: 5m
        labels:
          severity: warning
          service: "security"
        annotations:
          summary: "Suspicious API activity"
          description: "High rate of 401 responses: {{ $value }} per second"

      # Business Logic Alerts
      - alert: AIResponseTimeHigh
        expr: histogram_quantile(0.95, rate(ai_response_duration_seconds_bucket[5m])) > 10
        for: 5m
        labels:
          severity: warning
          service: "ai"
        annotations:
          summary: "AI response time is high"
          description: "95th percentile AI response time is {{ $value }}s"

      - alert: UserRegistrationRateHigh
        expr: rate(user_registrations_total[5m]) > 100
        for: 5m
        labels:
          severity: info
          service: "business"
        annotations:
          summary: "High user registration rate"
          description: "User registration rate is {{ $value }} per second"

      - alert: PaymentFailureRateHigh
        expr: rate(payment_failures_total[5m]) / rate(payment_attempts_total[5m]) > 0.1
        for: 5m
        labels:
          severity: warning
          service: "payment"
        annotations:
          summary: "High payment failure rate"
          description: "Payment failure rate is {{ $value | humanizePercentage }}"

  - name: sla.rules
    rules:
      # SLA Recording Rules
      - record: sla:availability_5m
        expr: avg_over_time(up[5m])

      - record: sla:error_rate_5m
        expr: rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m])

      - record: sla:latency_p95_5m
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))

      - record: sla:latency_p99_5m
        expr: histogram_quantile(0.99, rate(http_request_duration_seconds_bucket[5m]))

      # SLA Alerts
      - alert: SLAAvailabilityBreach
        expr: sla:availability_5m < 0.999
        for: 1m
        labels:
          severity: critical
          sla: "availability"
        annotations:
          summary: "SLA availability breach"
          description: "Service availability is {{ $value | humanizePercentage }}, below 99.9% SLA"

      - alert: SLAErrorRateBreach
        expr: sla:error_rate_5m > 0.001
        for: 5m
        labels:
          severity: critical
          sla: "error_rate"
        annotations:
          summary: "SLA error rate breach"
          description: "Error rate is {{ $value | humanizePercentage }}, above 0.1% SLA"

      - alert: SLALatencyBreach
        expr: sla:latency_p95_5m > 0.5
        for: 5m
        labels:
          severity: warning
          sla: "latency"
        annotations:
          summary: "SLA latency breach"
          description: "95th percentile latency is {{ $value }}s, above 500ms SLA"